{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kelly-10_nlp_own_code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kellyslpang/unpackAIworkbooks/blob/main/Kelly_10_nlp_own_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3T-2NPIRRE-"
      },
      "source": [
        "# NLP Deep Dive - Own Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcF86rzkRV0m"
      },
      "source": [
        "Own refactored code and notes for *Chapter 10: NLP Deep Dive: RNNs* ([`10_nlp.ipynb`](https://colab.research.google.com/github/vtecftwy/fastbook/blob/master/10_nlp.ipynb))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsaHv4EvRhEn"
      },
      "source": [
        "## Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPjNlZiJTrp4"
      },
      "source": [
        "It is recommended that you work in two steps:\n",
        "1. Copy the code from the fastbook notebook and make sure it works\n",
        "2. Refactor (i.e. rewrite the code in your own style) by \n",
        "    - regrouping things together that make sense to you\n",
        "    - adding text cells to explain what to code does in your own words and possible references to the doc you may have consulsted\n",
        "    - deleting code you think was only there to explain things but are not required once you run models end to end\n",
        "\n",
        "When you have done that, you get a customized reference notebook for you which you can consult later on when you forgot the details, withouht having to read the full notebook from fastbook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0HodndDt7ih"
      },
      "source": [
        "## Your code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQ_iZ_G0t9sD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32cb8305-0115-4f94-9a48-f14250083214"
      },
      "source": [
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()\n",
        "from fastbook import *\n",
        "from IPython.display import display,HTML"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 720 kB 7.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 46 kB 5.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 188 kB 59.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 59.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 4.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 51 kB 397 kB/s \n",
            "\u001b[?25hMounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "-Y88fz_69p7k",
        "outputId": "0fafaee8-380a-4b20-fa7a-1735128d9bc8"
      },
      "source": [
        "from fastai.text.all import *\n",
        "path = untar_data(URLs.IMDB)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='144441344' class='' max='144440600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [144441344/144440600 00:03<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hu4aWfdc9ufE",
        "outputId": "3222b354-1c89-4112-c60a-ba5c0d3595b5"
      },
      "source": [
        "# 1. List all the folders under path (using the path.iterdir() method)\n",
        "print(f\"path to dataset: {path.absolute()}\")\n",
        "[f\"{'file:  ' if p.is_file() else 'folder:'} {p.name}\" for p in path.iterdir()]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "path to dataset: /root/.fastai/data/imdb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['file:   README',\n",
              " 'folder: unsup',\n",
              " 'folder: train',\n",
              " 'folder: test',\n",
              " 'file:   imdb.vocab',\n",
              " 'folder: tmp_lm',\n",
              " 'folder: tmp_clas']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mQiX9G99vel",
        "outputId": "43140866-70dd-469f-f8c2-79d347ad5091"
      },
      "source": [
        "# 2. Get the full text of README\n",
        "with open(path/'README', mode='r') as f:\n",
        "    txt = f.readlines()\n",
        "print(''.join(txt))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Large Movie Review Dataset v1.0\n",
            "\n",
            "Overview\n",
            "\n",
            "This dataset contains movie reviews along with their associated binary\n",
            "sentiment polarity labels. It is intended to serve as a benchmark for\n",
            "sentiment classification. This document outlines how the dataset was\n",
            "gathered, and how to use the files provided. \n",
            "\n",
            "Dataset \n",
            "\n",
            "The core dataset contains 50,000 reviews split evenly into 25k train\n",
            "and 25k test sets. The overall distribution of labels is balanced (25k\n",
            "pos and 25k neg). We also include an additional 50,000 unlabeled\n",
            "documents for unsupervised learning. \n",
            "\n",
            "In the entire collection, no more than 30 reviews are allowed for any\n",
            "given movie because reviews for the same movie tend to have correlated\n",
            "ratings. Further, the train and test sets contain a disjoint set of\n",
            "movies, so no significant performance is obtained by memorizing\n",
            "movie-unique terms and their associated with observed labels.  In the\n",
            "labeled train/test sets, a negative review has a score <= 4 out of 10,\n",
            "and a positive review has a score >= 7 out of 10. Thus reviews with\n",
            "more neutral ratings are not included in the train/test sets. In the\n",
            "unsupervised set, reviews of any rating are included and there are an\n",
            "even number of reviews > 5 and <= 5.\n",
            "\n",
            "Files\n",
            "\n",
            "There are two top-level directories [train/, test/] corresponding to\n",
            "the training and test sets. Each contains [pos/, neg/] directories for\n",
            "the reviews with binary labels positive and negative. Within these\n",
            "directories, reviews are stored in text files named following the\n",
            "convention [[id]_[rating].txt] where [id] is a unique id and [rating] is\n",
            "the star rating for that review on a 1-10 scale. For example, the file\n",
            "[test/pos/200_8.txt] is the text for a positive-labeled test set\n",
            "example with unique id 200 and star rating 8/10 from IMDb. The\n",
            "[train/unsup/] directory has 0 for all ratings because the ratings are\n",
            "omitted for this portion of the dataset.\n",
            "\n",
            "We also include the IMDb URLs for each review in a separate\n",
            "[urls_[pos, neg, unsup].txt] file. A review with unique id 200 will\n",
            "have its URL on line 200 of this file. Due the ever-changing IMDb, we\n",
            "are unable to link directly to the review, but only to the movie's\n",
            "review page.\n",
            "\n",
            "In addition to the review text files, we include already-tokenized bag\n",
            "of words (BoW) features that were used in our experiments. These \n",
            "are stored in .feat files in the train/test directories. Each .feat\n",
            "file is in LIBSVM format, an ascii sparse-vector format for labeled\n",
            "data.  The feature indices in these files start from 0, and the text\n",
            "tokens corresponding to a feature index is found in [imdb.vocab]. So a\n",
            "line with 0:7 in a .feat file means the first word in [imdb.vocab]\n",
            "(the) appears 7 times in that review.\n",
            "\n",
            "LIBSVM page for details on .feat file format:\n",
            "http://www.csie.ntu.edu.tw/~cjlin/libsvm/\n",
            "\n",
            "We also include [imdbEr.txt] which contains the expected rating for\n",
            "each token in [imdb.vocab] as computed by (Potts, 2011). The expected\n",
            "rating is a good way to get a sense for the average polarity of a word\n",
            "in the dataset.\n",
            "\n",
            "Citing the dataset\n",
            "\n",
            "When using this dataset please cite our ACL 2011 paper which\n",
            "introduces it. This paper also contains classification results which\n",
            "you may want to compare against.\n",
            "\n",
            "\n",
            "@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
            "  author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
            "  title     = {Learning Word Vectors for Sentiment Analysis},\n",
            "  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
            "  month     = {June},\n",
            "  year      = {2011},\n",
            "  address   = {Portland, Oregon, USA},\n",
            "  publisher = {Association for Computational Linguistics},\n",
            "  pages     = {142--150},\n",
            "  url       = {http://www.aclweb.org/anthology/P11-1015}\n",
            "}\n",
            "\n",
            "References\n",
            "\n",
            "Potts, Christopher. 2011. On the negativity of negation. In Nan Li and\n",
            "David Lutz, eds., Proceedings of Semantics and Linguistic Theory 20,\n",
            "636-659.\n",
            "\n",
            "Contact\n",
            "\n",
            "For questions/comments/corrections please contact Andrew Maas\n",
            "amaas@cs.stanford.edu\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "id": "kL6qz5MV-BX6",
        "outputId": "4d04307b-a70c-44f5-c3ce-2e9bce84d12a"
      },
      "source": [
        "# List the folders and list the files\n",
        "print('Folders:')\n",
        "display([p.name for p in path.iterdir() if p.is_dir()])\n",
        "print('Files:')\n",
        "display([p.name for p in path.iterdir() if p.is_file()])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Folders:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['unsup', 'train', 'test', 'tmp_lm', 'tmp_clas']"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Files:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['README', 'imdb.vocab']"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjJwIHko-B87",
        "outputId": "1642fe22-446b-443c-eeb0-7de52b308e80"
      },
      "source": [
        "# Content of the training set (in train folder), test/validation set (in test folder) and in unsupervised (excluding text files)\n",
        "[p.name for p in (path/'train').iterdir()], [p.name for p in (path/'test').iterdir()], [p.name for p in (path/'unsup').iterdir() if 'txt' not in p.suffix]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['labeledBow.feat', 'neg', 'pos', 'unsupBow.feat'],\n",
              " ['labeledBow.feat', 'neg', 'pos'],\n",
              " [])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYS068gC-NDm",
        "outputId": "434fb153-8954-40d5-c40f-308c995bf12d"
      },
      "source": [
        "# First files for training in the positive review folder (pos) and negative review (neg). As mentioned in read.me the format is id_rating.txt\n",
        "[p.name for p in (path/'train/pos').iterdir()][:5], [p.name for p in (path/'train/neg').iterdir()][:5]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['7236_8.txt', '3889_10.txt', '8885_10.txt', '7490_8.txt', '5845_7.txt'],\n",
              " ['10311_3.txt', '8879_4.txt', '6222_1.txt', '4851_3.txt', '8626_1.txt'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5gyHFl3-SII",
        "outputId": "20b4e58f-9725-440e-fb27-967b12bd9fb0"
      },
      "source": [
        "# First files for testing in the positive review folder (pos) and negative review (neg). As mentioned in read.me the format is id_rating.txt\n",
        "[p.name for p in (path/'test/pos').iterdir()][:5], [p.name for p in (path/'test/neg').iterdir()][:5]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['7814_8.txt', '2943_10.txt', '4776_8.txt', '177_8.txt', '8338_7.txt'],\n",
              " ['8879_4.txt', '4866_3.txt', '6222_1.txt', '9901_1.txt', '7848_2.txt'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1u2kAq2J-USw",
        "outputId": "50cc3d3c-f5b2-48ee-8471-e56f9a5e715e"
      },
      "source": [
        "# First files in unsup folder (pos). As mentioned in read.me the format is id_rating.txt, where rating is 0\n",
        "[p.name for p in (path/'unsup').iterdir()][:5]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['5962_0.txt', '49064_0.txt', '10550_0.txt', '25322_0.txt', '593_0.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98ldzqhf-Yj5",
        "outputId": "f39515fd-2f39-483f-b2f6-9a1cbc638461"
      },
      "source": [
        "files = get_text_files(path, folders = ['train', 'test', 'unsup'])\n",
        "files"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#100000) [Path('/root/.fastai/data/imdb/train/neg/428_1.txt'),Path('/root/.fastai/data/imdb/train/neg/4231_1.txt'),Path('/root/.fastai/data/imdb/train/neg/10597_2.txt'),Path('/root/.fastai/data/imdb/train/neg/4184_4.txt'),Path('/root/.fastai/data/imdb/train/neg/6746_1.txt'),Path('/root/.fastai/data/imdb/train/neg/4399_4.txt'),Path('/root/.fastai/data/imdb/train/neg/1534_1.txt'),Path('/root/.fastai/data/imdb/train/neg/7054_2.txt'),Path('/root/.fastai/data/imdb/train/neg/1785_2.txt'),Path('/root/.fastai/data/imdb/train/neg/2131_2.txt')...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "IYKB4mlp-gPs",
        "outputId": "08a30762-dcf7-4660-f9dd-bfc0d42d8b47"
      },
      "source": [
        "txt = files[1].open().read()\n",
        "txt[:150]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I felt obliged to watch this movie all the way through, since I had found it in a bargain bin and bought it for my own, but I came close many times to'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gh_OnLX3-wvL",
        "outputId": "2c8892e9-8dda-4d90-9be4-b810840e98de"
      },
      "source": [
        "spacy = WordTokenizer()\n",
        "toks = first(spacy([txt]))\n",
        "print(coll_repr(toks, 30))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(#275) ['I','felt','obliged','to','watch','this','movie','all','the','way','through',',','since','I','had','found','it','in','a','bargain','bin','and','bought','it','for','my','own',',','but','I'...]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPuvOEr7BBDY",
        "outputId": "0d29703d-29c2-4a05-9c66-3402009b7943"
      },
      "source": [
        "first(spacy(['The U.S. dollar $1 is $1.00.']))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#9) ['The','U.S.','dollar','$','1','is','$','1.00','.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Pb35wUJBCnu",
        "outputId": "f1fb2943-f6b1-4ced-a534-6f7e2e154889"
      },
      "source": [
        "tkn = Tokenizer(spacy)\n",
        "print(coll_repr(tkn('The U.S. dollar $1 is $1.00.'),20))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(#13) ['xxbos','xxmaj','the','xxup','u.s','.','dollar','$','1','is','$','1.00','.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7n15NzFoBECT",
        "outputId": "34427d62-b70e-450a-bd48-00fc34d68af4"
      },
      "source": [
        "tkn = Tokenizer(spacy)\n",
        "print(coll_repr(tkn(txt), 31))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(#292) ['xxbos','i','felt','obliged','to','watch','this','movie','all','the','way','through',',','since','i','had','found','it','in','a','bargain','bin','and','bought','it','for','my','own',',','but','i'...]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIAVYNz4BHPC",
        "outputId": "d2481725-a1f9-4e55-9ecb-10aab7a53542"
      },
      "source": [
        "defaults.text_proc_rules"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<function fastai.text.core.fix_html>,\n",
              " <function fastai.text.core.replace_rep>,\n",
              " <function fastai.text.core.replace_wrep>,\n",
              " <function fastai.text.core.spec_add_spaces>,\n",
              " <function fastai.text.core.rm_useless_spaces>,\n",
              " <function fastai.text.core.replace_all_caps>,\n",
              " <function fastai.text.core.replace_maj>,\n",
              " <function fastai.text.core.lowercase>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QyCszNnsBKl2",
        "outputId": "f4ab0d39-8993-4b8b-fd65-0fdd28293f1f"
      },
      "source": [
        "coll_repr(tkn('&copy;   Fast.ai www.fast.ai/INDEX'), 31)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"(#11) ['xxbos','©','xxmaj','fast.ai','xxrep','3','w','.fast.ai','/','xxup','index']\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "-tZQ3WRNBRj0",
        "outputId": "9bc77a5c-0168-4b6f-a7a6-a39a3331a039"
      },
      "source": [
        "tokens = spacy([txt])\n",
        "display(tokens)\n",
        "\n",
        "tokens = spacy([txt])\n",
        "display(next(tokens, None))\n",
        "\n",
        "tokens = spacy([txt])\n",
        "display(first(tokens))\n",
        "\n",
        "txt0 = files[0].open().read()\n",
        "print(1, ': ', txt0[0:90])\n",
        "txt1 = files[1].open().read()\n",
        "print(2, ': ', txt1[0:90])\n",
        "txt2 = files[2].open().read()\n",
        "print(3, ': ', txt2[0:90])\n",
        "\n",
        "txt_collection = [txt0, txt1, txt2]\n",
        "toks_collection = spacy(txt_collection)\n",
        "display(first(toks_collection))\n",
        "display(first(toks_collection))\n",
        "display(first(toks_collection))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<generator object SpacyTokenizer.__call__.<locals>.<genexpr> at 0x7f4a757b9650>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(#450) ['Well',',','where','to','start','?','I','want','to','start'...]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(#450) ['Well',',','where','to','start','?','I','want','to','start'...]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1 :  The story is completely different from the video game. I liked that. You don't know whats \n",
            "2 :  Well, where to start? I want to start off by saying that this movie was pretty bad, but th\n",
            "3 :  This show is different, thats for sure. It lacks the slap stick humor your used to when wa\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(#154) ['The','story','is','completely','different','from','the','video','game','.'...]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(#450) ['Well',',','where','to','start','?','I','want','to','start'...]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(#220) ['This','show','is','different',',','that','s','for','sure','.'...]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8-3Zf2-BVsZ"
      },
      "source": [
        "### Subword Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qnDEdHxBZdf"
      },
      "source": [
        "txts = L(o.open().read() for o in files[:2000])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjZ0vZKxBcVf"
      },
      "source": [
        "def subword(sz):\n",
        "    sp = SubwordTokenizer(vocab_sz=sz)\n",
        "    sp.setup(txts)\n",
        "    return ' '.join(first(sp([txt]))[:40])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "V8DR8hUXBfJi",
        "outputId": "9bfb7137-785c-46ca-8c83-302537925123"
      },
      "source": [
        "subword(1000)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'▁I ▁felt ▁ob li g ed ▁to ▁watch ▁this ▁movie ▁all ▁the ▁way ▁through , ▁since ▁I ▁had ▁found ▁it ▁in ▁a ▁b ar g ain ▁b in ▁and ▁b ough t ▁it ▁for ▁my ▁own , ▁but ▁I ▁came'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "T4zG5e7aBwhF",
        "outputId": "45a8d4f8-859e-4e2f-c395-ff11d208a475"
      },
      "source": [
        "subword(200)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'▁ W e ll , ▁w h er e ▁to ▁ st ar t ? ▁I ▁w an t ▁to ▁ st ar t ▁of f ▁b y ▁s ay ing ▁that ▁this ▁movie ▁was ▁p re t t y'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "j756mXU3B1Dw",
        "outputId": "022153fd-1a71-42ca-b9fa-47a904db5f2f"
      },
      "source": [
        "subword(10000)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'▁Well , ▁where ▁to ▁start ? ▁I ▁want ▁to ▁start ▁off ▁by ▁saying ▁that ▁this ▁movie ▁was ▁pretty ▁bad , ▁but ▁the ▁gratuitous ▁nudity ▁was ▁comfort ing . ▁This ▁movie ▁runs ▁about ▁8 7 ▁minutes , ▁which ▁is ▁amazing ▁considering'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1prXpOWLCBXt"
      },
      "source": [
        "### Numericalization with fastai"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HPafto4CBHA",
        "outputId": "bdd6812d-034b-4d80-816e-e1894b69f2fc"
      },
      "source": [
        "toks = tkn(txt)\n",
        "print(coll_repr(tkn(txt), 31))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(#292) ['xxbos','i','felt','obliged','to','watch','this','movie','all','the','way','through',',','since','i','had','found','it','in','a','bargain','bin','and','bought','it','for','my','own',',','but','i'...]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8UEMWmHCJ1t",
        "outputId": "f37ec56d-fa12-4bf0-ab44-f378bdb036e8"
      },
      "source": [
        "toks200 = txts[:200].map(tkn)\n",
        "toks200[0]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#78) ['xxbos','xxmaj','wow',',','a','movie','about','xxup','nyc','politics'...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "w7jt_6StCP-y",
        "outputId": "3f494973-7c6c-4123-aab4-778691691c62"
      },
      "source": [
        "num = Numericalize()\n",
        "num.setup(toks200)\n",
        "coll_repr(num.vocab,20)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"(#2184) ['xxunk','xxpad','xxbos','xxeos','xxfld','xxrep','xxwrep','xxup','xxmaj','the','.',',','a','and','of','to','is','it','i','in'...]\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5PNzcTICj8P",
        "outputId": "8feebcce-990f-47b9-844c-45767feb39cc"
      },
      "source": [
        "nums = num(toks)[:20]\n",
        "nums"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorText([  2,  18, 335,   0,  15, 127,  21,  27,  46,   9, 118, 163,  11, 235,  18,  77, 363,  17,  19,  12])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wZUiznVaCnB9",
        "outputId": "47f0028a-eff6-4c55-da32-47ea7dfd1353"
      },
      "source": [
        "' '.join(num.vocab[o] for o in nums)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'xxbos i felt xxunk to watch this movie all the way through , since i had found it in a'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAINEVmpCzsB"
      },
      "source": [
        "### Putting Our Texts into Batches for a Language Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "fRAvwpqvC0vR",
        "outputId": "09d08e83-d145-416c-97b5-d74abcbd9699"
      },
      "source": [
        "stream = \"In this chapter, we will go back over the example of classifying movie reviews we studied in chapter 1 and dig deeper under the surface. First we will look at the processing steps necessary to convert text into numbers and how to customize it. By doing this, we'll have another example of the PreProcessor used in the data block API.\\nThen we will study how we build a language model and train it for a while.\"\n",
        "tokens = tkn(stream)\n",
        "\n",
        "bs, seq_len = 6, 15\n",
        "\n",
        "d_tokens = np.array([tokens[i*seq_len:(i+1)*seq_len] for i in range(bs)])\n",
        "\n",
        "df = pd.DataFrame(d_tokens)\n",
        "\n",
        "display(HTML(df.to_html(index=False,header=None)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>xxbos</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>in</td>\n",
              "      <td>this</td>\n",
              "      <td>chapter</td>\n",
              "      <td>,</td>\n",
              "      <td>we</td>\n",
              "      <td>will</td>\n",
              "      <td>go</td>\n",
              "      <td>back</td>\n",
              "      <td>over</td>\n",
              "      <td>the</td>\n",
              "      <td>example</td>\n",
              "      <td>of</td>\n",
              "      <td>classifying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>movie</td>\n",
              "      <td>reviews</td>\n",
              "      <td>we</td>\n",
              "      <td>studied</td>\n",
              "      <td>in</td>\n",
              "      <td>chapter</td>\n",
              "      <td>1</td>\n",
              "      <td>and</td>\n",
              "      <td>dig</td>\n",
              "      <td>deeper</td>\n",
              "      <td>under</td>\n",
              "      <td>the</td>\n",
              "      <td>surface</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>first</td>\n",
              "      <td>we</td>\n",
              "      <td>will</td>\n",
              "      <td>look</td>\n",
              "      <td>at</td>\n",
              "      <td>the</td>\n",
              "      <td>processing</td>\n",
              "      <td>steps</td>\n",
              "      <td>necessary</td>\n",
              "      <td>to</td>\n",
              "      <td>convert</td>\n",
              "      <td>text</td>\n",
              "      <td>into</td>\n",
              "      <td>numbers</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>how</td>\n",
              "      <td>to</td>\n",
              "      <td>customize</td>\n",
              "      <td>it</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>by</td>\n",
              "      <td>doing</td>\n",
              "      <td>this</td>\n",
              "      <td>,</td>\n",
              "      <td>we</td>\n",
              "      <td>'ll</td>\n",
              "      <td>have</td>\n",
              "      <td>another</td>\n",
              "      <td>example</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>of</td>\n",
              "      <td>the</td>\n",
              "      <td>preprocessor</td>\n",
              "      <td>used</td>\n",
              "      <td>in</td>\n",
              "      <td>the</td>\n",
              "      <td>data</td>\n",
              "      <td>block</td>\n",
              "      <td>xxup</td>\n",
              "      <td>api</td>\n",
              "      <td>.</td>\n",
              "      <td>\\n</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>then</td>\n",
              "      <td>we</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>will</td>\n",
              "      <td>study</td>\n",
              "      <td>how</td>\n",
              "      <td>we</td>\n",
              "      <td>build</td>\n",
              "      <td>a</td>\n",
              "      <td>language</td>\n",
              "      <td>model</td>\n",
              "      <td>and</td>\n",
              "      <td>train</td>\n",
              "      <td>it</td>\n",
              "      <td>for</td>\n",
              "      <td>a</td>\n",
              "      <td>while</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "FJ9veZjqDQrz",
        "outputId": "3c67aa4d-2f0e-4e50-c548-651bc03e08dd"
      },
      "source": [
        "bs,seq_len = 6, 5\n",
        "d_tokens = np.array([tokens[i*15:i*15+seq_len] for i in range(bs)])\n",
        "df = pd.DataFrame(d_tokens)\n",
        "display(HTML(df.to_html(index=False,header=None)))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>xxbos</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>in</td>\n",
              "      <td>this</td>\n",
              "      <td>chapter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>movie</td>\n",
              "      <td>reviews</td>\n",
              "      <td>we</td>\n",
              "      <td>studied</td>\n",
              "      <td>in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>first</td>\n",
              "      <td>we</td>\n",
              "      <td>will</td>\n",
              "      <td>look</td>\n",
              "      <td>at</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>how</td>\n",
              "      <td>to</td>\n",
              "      <td>customize</td>\n",
              "      <td>it</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>of</td>\n",
              "      <td>the</td>\n",
              "      <td>preprocessor</td>\n",
              "      <td>used</td>\n",
              "      <td>in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>will</td>\n",
              "      <td>study</td>\n",
              "      <td>how</td>\n",
              "      <td>we</td>\n",
              "      <td>build</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "Wnpq2hmADhCI",
        "outputId": "b3c037b2-3a8b-4ced-83f9-e836ec84617f"
      },
      "source": [
        "bs,seq_len = 6,5\n",
        "d_tokens = np.array([tokens[i*15+10:i*15+15] for i in range(bs)])\n",
        "df = pd.DataFrame(d_tokens)\n",
        "display(HTML(df.to_html(index=False,header=None)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>over</td>\n",
              "      <td>the</td>\n",
              "      <td>example</td>\n",
              "      <td>of</td>\n",
              "      <td>classifying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>under</td>\n",
              "      <td>the</td>\n",
              "      <td>surface</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>convert</td>\n",
              "      <td>text</td>\n",
              "      <td>into</td>\n",
              "      <td>numbers</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>we</td>\n",
              "      <td>'ll</td>\n",
              "      <td>have</td>\n",
              "      <td>another</td>\n",
              "      <td>example</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>.</td>\n",
              "      <td>\\n</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>then</td>\n",
              "      <td>we</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>it</td>\n",
              "      <td>for</td>\n",
              "      <td>a</td>\n",
              "      <td>while</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPxFWF4gD8LE"
      },
      "source": [
        " We create an LMDataLoader. We do this by first applying our Numericalize object to the tokenized texts:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfyIlfkgD-6j"
      },
      "source": [
        "nums200 = toks200.map(num)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTAyPEj_EDiP"
      },
      "source": [
        "dl = LMDataLoader(nums200)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kyvY0NWEGMz",
        "outputId": "9cff9236-c030-4ade-fe98-efbd2c0496a1"
      },
      "source": [
        "x, y = first(dl)\n",
        "x.shape, y.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 72]), torch.Size([64, 72]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kXwJVrciERF2",
        "outputId": "2a96d8ee-c5a3-4516-e35d-a612be351f52"
      },
      "source": [
        "' '.join(num.vocab[o] for o in x[0][:20])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'xxbos xxmaj wow , a movie about xxup nyc xxunk seemingly written by someone who has never set foot in'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-oKze0wUET7j",
        "outputId": "2b622fbf-0f0b-4a12-c1d0-3b5d00ef4fff"
      },
      "source": [
        "' '.join(num.vocab[o] for o in y[0][:20])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'xxmaj wow , a movie about xxup nyc xxunk seemingly written by someone who has never set foot in xxup'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDGxpLk5EaQv"
      },
      "source": [
        "## Training a Text Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEuWhScnEdmz"
      },
      "source": [
        "Language Model Using DataBlock"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "TMk4zNTwEhKe",
        "outputId": "5019bac9-b1a7-44c8-8e69-68242c1599cf"
      },
      "source": [
        "get_imdb = partial(get_text_files, folders=['train', 'test', 'unsup'])\n",
        "\n",
        "dls_lm = DataBlock(blocks=TextBlock.from_folder(path, is_lm=True),\n",
        "                   get_items=get_imdb, splitter=RandomSplitter(0.1)\n",
        "                   ).dataloaders(path, path=path, bs=128, seq_len=80)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "O1BN5HL8FAri",
        "outputId": "9f6c4995-0be2-409e-ebb0-39ee0b2923ed"
      },
      "source": [
        "dls_lm.show_batch(max_n=5)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xxbos xxmaj it plays like your usual teenage - audience xxup t&amp;a movie , but the sentiment is incredibly bleak . xxmaj if it was made today , it 'd be considered an art house movie . xxmaj it goes through the usual routine of a guy trying to get laid , but the results of his efforts are harsh and cruel and unsatisfying . \\n\\n xxmaj the whole teen flick formula is adhered to , but nothing turns out</td>\n",
              "      <td>xxmaj it plays like your usual teenage - audience xxup t&amp;a movie , but the sentiment is incredibly bleak . xxmaj if it was made today , it 'd be considered an art house movie . xxmaj it goes through the usual routine of a guy trying to get laid , but the results of his efforts are harsh and cruel and unsatisfying . \\n\\n xxmaj the whole teen flick formula is adhered to , but nothing turns out the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\n\\n xxmaj this is a two - hour film and not the typical action - packed macho xxmaj will xxmaj smith film . xxmaj in fact , the most shocking aspect might be seeing the drawn , sad face of xxmaj smith throughout this story . xxmaj it almost does n't even look like him in a number of shots . xxmaj he looks like he 's lost weight and is sick . xxmaj smith does a great job portraying</td>\n",
              "      <td>xxmaj this is a two - hour film and not the typical action - packed macho xxmaj will xxmaj smith film . xxmaj in fact , the most shocking aspect might be seeing the drawn , sad face of xxmaj smith throughout this story . xxmaj it almost does n't even look like him in a number of shots . xxmaj he looks like he 's lost weight and is sick . xxmaj smith does a great job portraying a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>old and long for the days before reality xxup tv ruled when good drama and sitcoms proliferated . xxbos no , i'm not a radical xxunk bashing the hentai and yaoi genre , i just find it really boring and xxunk god , i was xxup made to watch this for initiation from some stupid punk and my my , even an xxup mst3k movie has a storyline , not to mention that this xxup hentai crap is what 's</td>\n",
              "      <td>and long for the days before reality xxup tv ruled when good drama and sitcoms proliferated . xxbos no , i'm not a radical xxunk bashing the hentai and yaoi genre , i just find it really boring and xxunk god , i was xxup made to watch this for initiation from some stupid punk and my my , even an xxup mst3k movie has a storyline , not to mention that this xxup hentai crap is what 's giving</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>xxmaj stone ) , an experienced hunter friend of xxmaj challenger . xxmaj prof . xxmaj summerlee ( arthur xxmaj hoyt ) goes as well , hoping to prove that xxmaj challenger is a fraud , and finally , reporter xxmaj edward xxmaj malone ( lloyd xxmaj hughes ) joins the expedition , hoping to prove his girlfriend xxmaj gladys ( alma xxmaj bennet ) that he is brave enough to face death . \\n\\n xxmaj cleverly adapted by xxmaj</td>\n",
              "      <td>stone ) , an experienced hunter friend of xxmaj challenger . xxmaj prof . xxmaj summerlee ( arthur xxmaj hoyt ) goes as well , hoping to prove that xxmaj challenger is a fraud , and finally , reporter xxmaj edward xxmaj malone ( lloyd xxmaj hughes ) joins the expedition , hoping to prove his girlfriend xxmaj gladys ( alma xxmaj bennet ) that he is brave enough to face death . \\n\\n xxmaj cleverly adapted by xxmaj broadway</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>intelligence too . xxmaj her xxmaj lady xxmaj marion was much more than a helpless female . xxmaj was she a damsel in distress ? xxmaj oh , most surely she was that , but not a screaming , whiny helpless girl . \\n\\n xxmaj basil xxmaj rathbone ( sir xxmaj guy of xxmaj gisbourne ) was perhaps the best villain in the business . xxmaj next to his characterization of xxmaj sherlock xxmaj holmes in all those films (</td>\n",
              "      <td>too . xxmaj her xxmaj lady xxmaj marion was much more than a helpless female . xxmaj was she a damsel in distress ? xxmaj oh , most surely she was that , but not a screaming , whiny helpless girl . \\n\\n xxmaj basil xxmaj rathbone ( sir xxmaj guy of xxmaj gisbourne ) was perhaps the best villain in the business . xxmaj next to his characterization of xxmaj sherlock xxmaj holmes in all those films ( and</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOMSHzuZFDlF"
      },
      "source": [
        "### Fine-Tuning the Language Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "-K3V2sNMFEgN",
        "outputId": "02d422a6-25e2-4b71-f97e-5c970826e7c5"
      },
      "source": [
        "learn = language_model_learner(dls_lm, AWD_LSTM, drop_mult=0.3, \n",
        "                               metrics=[accuracy, Perplexity()]\n",
        "                               ).to_fp16()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='105070592' class='' max='105067061' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [105070592/105067061 00:02<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "oJZ_3oGsFeUM",
        "outputId": "f9ef087c-7d28-4cb7-8203-aaff58c2914c"
      },
      "source": [
        "learn.fit_one_cycle(1, 2e-2)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.015255</td>\n",
              "      <td>3.896605</td>\n",
              "      <td>0.300395</td>\n",
              "      <td>49.235023</td>\n",
              "      <td>21:10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tltGBVBrFxeW"
      },
      "source": [
        "### Saving and Loading Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dCWIjv5Fzbe",
        "outputId": "008fe976-0730-4570-8078-2e221aa9fa12"
      },
      "source": [
        "learn.save('1epoch')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('/root/.fastai/data/imdb/models/1epoch.pth')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSZCXmmjF25d"
      },
      "source": [
        "learn = learn.load('1epoch')"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "x_tPDuAYF4sx",
        "outputId": "056ad162-fd4a-45c7-b976-5f217b162a8d"
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(10, 2e-3)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.757856</td>\n",
              "      <td>3.752456</td>\n",
              "      <td>0.317064</td>\n",
              "      <td>42.625660</td>\n",
              "      <td>22:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.700445</td>\n",
              "      <td>3.695680</td>\n",
              "      <td>0.323698</td>\n",
              "      <td>40.272964</td>\n",
              "      <td>22:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.634137</td>\n",
              "      <td>3.644895</td>\n",
              "      <td>0.329365</td>\n",
              "      <td>38.278748</td>\n",
              "      <td>23:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.571423</td>\n",
              "      <td>3.614856</td>\n",
              "      <td>0.332681</td>\n",
              "      <td>37.145996</td>\n",
              "      <td>23:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3.501326</td>\n",
              "      <td>3.590635</td>\n",
              "      <td>0.336075</td>\n",
              "      <td>36.257084</td>\n",
              "      <td>23:32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>3.444747</td>\n",
              "      <td>3.573214</td>\n",
              "      <td>0.338475</td>\n",
              "      <td>35.630913</td>\n",
              "      <td>23:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>3.375748</td>\n",
              "      <td>3.565423</td>\n",
              "      <td>0.339745</td>\n",
              "      <td>35.354424</td>\n",
              "      <td>23:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>3.293104</td>\n",
              "      <td>3.562633</td>\n",
              "      <td>0.340946</td>\n",
              "      <td>35.255905</td>\n",
              "      <td>23:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>3.249682</td>\n",
              "      <td>3.564199</td>\n",
              "      <td>0.341284</td>\n",
              "      <td>35.311157</td>\n",
              "      <td>22:51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>3.224097</td>\n",
              "      <td>3.568984</td>\n",
              "      <td>0.341065</td>\n",
              "      <td>35.480511</td>\n",
              "      <td>23:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrvjbXbtGDhQ"
      },
      "source": [
        "learn.save_encoder('finetuned')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5VCmwnVLJ8P",
        "outputId": "83a023c9-076e-4f9c-aee4-818db8ef3d4a"
      },
      "source": [
        "!ls /root/.fastai/data/imdb/models/\n",
        "\n",
        "\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1epoch.pth  finetuned.pth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McpSuk7-LvM6",
        "outputId": "b530cc89-679e-47b9-8d11-bb87606cf0d6"
      },
      "source": [
        "!ls /content/gdrive/MyDrive/ai/nb10"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finetuned.pth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne6ycUpcJvU3"
      },
      "source": [
        "path2 = Path('gdrive/MyDrive/ai/nb10')\n",
        "!cp /root/.fastai/data/imdb/models/finetuned.pth /content/gdrive/MyDrive/ai/nb10"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2vNwFg7GWOe"
      },
      "source": [
        "### Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "EIb-kt4eGWzo",
        "outputId": "e6cd3f95-59ac-4d1d-8a14-ab828d07393f"
      },
      "source": [
        "TEXT = \"I liked this movie because\"\n",
        "N_WORDS = 40\n",
        "N_SENTENCES = 2\n",
        "preds = [learn.predict(TEXT, N_WORDS, temperature=0.75) \n",
        "         for _ in range(N_SENTENCES)]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87dq1hmDGju4",
        "outputId": "a02e9126-9188-49e3-8592-c1826e4b67aa"
      },
      "source": [
        "print(\"\\n\".join(preds))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i liked this movie because the storyline was very well done . It had one of the best movies ever made . It was like a big budget film made on a lot of budget , but i did n't think it was\n",
            "i liked this movie because it was really about a boy 's father who has a son who wants to take care of his father who is a Texan . That 's the way the movie was filmed called Miami . \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzungVydG3Et"
      },
      "source": [
        "### Creating the Classifier DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLHSByHqG3tS"
      },
      "source": [
        "dls_clas = DataBlock(\n",
        "    blocks=(TextBlock.from_folder(path, vocab=dls_lm.vocab),CategoryBlock),\n",
        "    get_y = parent_label,\n",
        "    get_items=partial(get_text_files, folders=['train', 'test']),\n",
        "    splitter=GrandparentSplitter(valid_name='test')\n",
        ").dataloaders(path, path=path, bs=128, seq_len=72)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "yfDip2oXHHZ2",
        "outputId": "6d1c0733-2fd6-4d7e-a574-0e5b5b54bf9c"
      },
      "source": [
        "dls_clas.show_batch(max_n=3)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xxbos xxmaj match 1 : xxmaj tag xxmaj team xxmaj table xxmaj match xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley vs xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley started things off with a xxmaj tag xxmaj team xxmaj table xxmaj match against xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit . xxmaj according to the rules of the match , both opponents have to go through tables in order to get the win . xxmaj benoit and xxmaj guerrero heated up early on by taking turns hammering first xxmaj spike and then xxmaj bubba xxmaj ray . a xxmaj german xxunk by xxmaj benoit to xxmaj bubba took the wind out of the xxmaj dudley brother . xxmaj spike tried to help his brother , but the referee restrained him while xxmaj benoit and xxmaj guerrero</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>xxbos * ! ! - xxup spoilers - ! ! * \\n\\n xxmaj before i begin this , let me say that i have had both the advantages of seeing this movie on the big screen and of having seen the \" authorized xxmaj version \" of this movie , remade by xxmaj stephen xxmaj king , himself , in 1997 . \\n\\n xxmaj both advantages made me appreciate this version of \" the xxmaj shining , \" all the more . \\n\\n xxmaj also , let me say that xxmaj i 've read xxmaj mr . xxmaj king 's book , \" the xxmaj shining \" on many occasions over the years , and while i love the book and am a huge fan of his work , xxmaj stanley xxmaj kubrick 's retelling of this story is far more compelling … and xxup scary . \\n\\n xxmaj kubrick</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>xxbos xxmaj warning : xxmaj does contain spoilers . \\n\\n xxmaj open xxmaj your xxmaj eyes \\n\\n xxmaj if you have not seen this film and plan on doing so , just stop reading here and take my word for it . xxmaj you have to see this film . i have seen it four times so far and i still have n't made up my mind as to what exactly happened in the film . xxmaj that is all i am going to say because if you have not seen this film , then stop reading right now . \\n\\n xxmaj if you are still reading then i am going to pose some questions to you and maybe if anyone has any answers you can email me and let me know what you think . \\n\\n i remember my xxmaj grade 11 xxmaj english teacher quite well . xxmaj</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0H7O6JRfIyej"
      },
      "source": [
        "There is one challenge we have to deal with, however, which is to do with collating multiple documents into a mini-batch. Let's see with an example, by trying to create a mini-batch containing the first 10 documents. First we'll numericalize them:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ano40tuOIv9O"
      },
      "source": [
        "nums_samp = toks200[:10].map(num)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYPhq7aNI1yu",
        "outputId": "8be08c04-7f41-4dd8-99c2-c8bf085ab6a1"
      },
      "source": [
        "nums_samp.map(len)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#10) [78,292,187,548,558,204,189,168,584,178]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSA1YQpRI9tB"
      },
      "source": [
        "learn = text_classifier_learner(dls_clas, AWD_LSTM, drop_mult=0.5, \n",
        "                                metrics=accuracy).to_fp16()"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYLNM3fcI_Rb"
      },
      "source": [
        "learn = learn.load_encoder('finetuned')"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2aSfEVnJJ4h"
      },
      "source": [
        "### Fine-Tuning the Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "T1qiqYsWJrJt",
        "outputId": "5848eff7-1168-4d90-ba2a-a3e8db9115c1"
      },
      "source": [
        "learn.fit_one_cycle(1, 2e-2)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.246536</td>\n",
              "      <td>0.183735</td>\n",
              "      <td>0.928600</td>\n",
              "      <td>01:09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "qPisS6NLJs_e",
        "outputId": "65428d04-ea75-4bc0-e807-c7db7fa6e98c"
      },
      "source": [
        "learn.freeze_to(-2)\n",
        "learn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.222068</td>\n",
              "      <td>0.165184</td>\n",
              "      <td>0.938320</td>\n",
              "      <td>01:14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "ef5lcEdLJ1Vz",
        "outputId": "66971428-e298-4a25-894d-a14a954e1071"
      },
      "source": [
        "learn.freeze_to(-3)\n",
        "learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.188739</td>\n",
              "      <td>0.148851</td>\n",
              "      <td>0.943800</td>\n",
              "      <td>01:33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "Zg7_kfqAJ3Om",
        "outputId": "8434ca5c-5ee3-4b5f-df82-6b2b34d2e07c"
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.159825</td>\n",
              "      <td>0.147953</td>\n",
              "      <td>0.945640</td>\n",
              "      <td>01:53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.152178</td>\n",
              "      <td>0.148020</td>\n",
              "      <td>0.945600</td>\n",
              "      <td>01:56</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjPjc-VLLju1"
      },
      "source": [
        "## Questionnaire"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8U-Jg1q4n1T"
      },
      "source": [
        "1. **What is \"self-supervised learning\"?**\n",
        "1. **What is a \"language model\"?**\n",
        "1. **Why is a language model considered self-supervised?**\n",
        "1. What are self-supervised models usually used for?\n",
        "1. **Why do we fine-tune language models?**\n",
        "1. What are the three steps to create a state-of-the-art text classifier?\n",
        "1. **How do the 50,000 unlabeled movie reviews help us create a better text classifier for the IMDb dataset?**\n",
        "1. What are the three steps to prepare your data for a language model?\n",
        "1. **What is \"tokenization\"? Why do we need it?**\n",
        "1. Name three different approaches to tokenization.\n",
        "1. **What is `xxbos`?**\n",
        "1. List four rules that fastai applies to text during tokenization.\n",
        "1. **Why are repeated characters replaced with a token showing the number of repetitions and the character that's repeated?**\n",
        "1. What is \"numericalization\"?\n",
        "1. **Why might there be words that are replaced with the \"unknown word\" token?**\n",
        "1. **With a batch size of 64, the first row of the tensor representing the first batch contains the first 64 tokens for the dataset. What does the second row of that tensor contain? What does the first row of the second batch contain?**\n",
        "1. Why do we need padding for text classification? Why don't we need it for language modeling?\n",
        "1. **What does an embedding matrix for NLP contain? What is its shape?**\n",
        "1. What is \"perplexity\"?\n",
        "1. Why do we have to pass the vocabulary of the language model to the classifier data block?\n",
        "1. What is \"gradual unfreezing\"?\n",
        "1. Why is text generation always likely to be ahead of automatic identification of machine-generated texts?"
      ]
    }
  ]
}